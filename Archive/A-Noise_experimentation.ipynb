{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10942f60-0228-4988-a94d-61e3b8fdc74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e143f573-f505-487d-a346-abc41250ed11",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Manual Allan Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea799c29-72b5-43ac-9d6b-8373b2c54e63",
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Here it is okay to use taus as a parameter, as we will recalculate the actual tau used based on meas_rate\n",
    "def manual_adev(data, meas_rate, taus):\n",
    "    N = data.size # number of data points present\n",
    "    averages = []   # can only make list of arrays, not array of arrays (but can convert to array of arrays after)\n",
    "    allan_variances = np.array([])\n",
    "    taus_actual = np.array([])\n",
    "    for tau in taus:\n",
    "        # If tau came from simulation (where tau=num_points/meas_rate), num should be very very close to an integer\n",
    "        # If tau came from us plugging in chosen values, round is probably best?\n",
    "        num = round(tau*meas_rate) # number of data points corresponding to sample of length tau\n",
    "        taus_actual = np.append(taus_actual, num/meas_rate)\n",
    "        remainder = N%num # remaining points that are not divisible by num\n",
    "        if remainder != 0:\n",
    "            data_cut = data[:-remainder] #cut off remaining points to make array divisible by num\n",
    "        else:\n",
    "            data_cut = data #without this, data[:0] will return an empty array\n",
    "        data_reshaped = data_cut.reshape(-1, num)\n",
    "        data_averages = np.mean(data_reshaped, axis=1)\n",
    "        averages.append(data_averages)   # again, this is the list (so use l.append(n))\n",
    "        #print('For tau = {:.2f}, array size = {:.2f}'.format(tau,data_averages.size))\n",
    "        #print('N = {:.2f}, num = {:.2f}, remainder = {:.2f}'.format(N, num, remainder))\n",
    "        #print('Data cut size = {:.2f}'.format(data_cut.size))\n",
    "        K = data_averages.size\n",
    "        diffs = np.diff(data_averages)\n",
    "        if K!=1:\n",
    "            var = np.sum(diffs**2) / (2*(K-1))\n",
    "        else:\n",
    "            var=0\n",
    "        allan_variances = np.append(allan_variances, var)\n",
    "    averages = np.array(averages, dtype=object)   # make list of arrays into array of arrays\n",
    "    return averages, allan_variances, taus_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2cce6-c18e-44a6-94a9-88b0ce4f6f9b",
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Here it is okay to use taus as a parameter becuase it's just for plotting purposes; taus isn't passed along anywhere\n",
    "def plot_adev(averages, allan_variances, taus):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    for tau,avg in zip(taus,averages):\n",
    "        N_avg = avg.size\n",
    "        #print('For tau = {:.2f}, T = {:.2f}'.format(tau, (N_avg-1) * tau))\n",
    "        times = np.linspace(0, (N_avg-1) * tau, N_avg) + tau/2\n",
    "        try:\n",
    "            plt.plot(times, avg, label = \"tau={:.2f}s\".format(tau), marker='.')\n",
    "        except ValueError:\n",
    "            print('Mismatch of dimensions for tau = {:.2f}'.format(tau))\n",
    "            print('avg.size = {:d}'.format(N_avg))\n",
    "            print('Giving np.arange(0, {:.2f}, {:.2f}) + {:.2f}/2'.format(N_avg*tau, tau, tau))\n",
    "            print('so times.size = {:d}'.format(times.size))\n",
    "    T = (averages[0].size-1) * taus[0]\n",
    "    #print(averages[0])\n",
    "    #print(taus[0])\n",
    "    #print('For first entry, T = {:.2f}'.format(T))\n",
    "    plt.xlim(0,T)\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(\"Data averaged over different times\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12,3))\n",
    "    plt.plot(taus, allan_variances, marker='o')\n",
    "    plt.xlabel(\"Averaging Time\")\n",
    "    plt.ylabel(\"Variance\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"Variance vs averaging time\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d51b1-6abc-4971-a7dc-bf82df511bc6",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Noise Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822be31a-45b9-425b-a8a9-e97dab356ebc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Simulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9a0a0-72d5-4257-a36a-7cb443f75b49",
   "metadata": {
    "code_folding": [
     2,
     15,
     30
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO: refer to paper for more definitive way to define noise spectrums\n",
    "# params most commonly used by engineers to characterize noise\n",
    "def generate_white_noise(N, meas_rate, seed=None):\n",
    "    if seed != None:\n",
    "        np.random.seed(seed+1) # seed for white noise\n",
    "    \n",
    "    white_noise = np.random.normal(0., 1., N) #N normally distributed points\n",
    "    # As meas_rate increases, the noise on each individual measurement should decrease since we're measuring\n",
    "    # more times in a single second (taking multiple measurements for (theoretically the same amount of noise)\n",
    "    # But as T increases, the noise in each measurement shouldn't change, since we're just measuring for longer\n",
    "    norm_const = np.sqrt(1/meas_rate)\n",
    "    white_noise *= norm_const # Normalize\n",
    "    \n",
    "    return white_noise\n",
    "\n",
    "def generate_brown_noise(N, meas_rate, seed=None):\n",
    "    if seed != None:\n",
    "        np.random.seed(seed+2) # different seed for brown noise\n",
    "    \n",
    "    white_noise = np.random.normal(0., 1., N) #N normally distributed points\n",
    "    # As meas_rate increases, the noise on each individual measurement should decrease since we're measuring\n",
    "    # more times in a single second (taking multiple measurements for (theoretically the same amount of noise)\n",
    "    # But as T increases, the noise in each measurement shouldn't change, since we're just measuring for longer\n",
    "    norm_const = np.sqrt(1/meas_rate)\n",
    "    white_noise *= norm_const # Normalize\n",
    "    \n",
    "    brown_noise = np.cumsum(white_noise) # each random point is a random walk step (cumilate steps)\n",
    "    \n",
    "    return brown_noise\n",
    "\n",
    "def generate_pink_noise(N, meas_rate, seed=None):\n",
    "    if seed != None:\n",
    "        np.random.seed(seed+3) # different seed for pink noise\n",
    "    \n",
    "    white_noise = np.random.normal(0., 1., N) #N normally distributed points\n",
    "    # As meas_rate increases, the noise on each individual measurement should decrease since we're measuring\n",
    "    # more times in a single second (taking multiple measurements for (theoretically the same amount of noise)\n",
    "    # But as T increases, the noise in each measurement shouldn't change, since we're just measuring for longer\n",
    "    norm_const = np.sqrt(1/meas_rate)\n",
    "    white_noise *= norm_const # Normalize\n",
    "    \n",
    "    brown_noise = np.cumsum(white_noise) # each random point is a random walk step (cumilate steps)\n",
    "    \n",
    "    pink_noise = brown_noise / np.max(np.abs(brown_noise)) #TODO: likely could be wrong\n",
    "    \n",
    "    return pink_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d017c223-c85f-4683-b9cc-359dcebf4581",
   "metadata": {
    "code_folding": [
     6
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We choose a paradigm of using N and meas_rate, and calculating T, since N is the main thing we need to keep\n",
    "# consistent across all functions.\n",
    "# We always re-calculate T=(N-1)/meas_rate (N-1 bc t.e. meas at 0) and never pass it on to another function.\n",
    "# N and T would also work, but if we chose to use T and meas_rate, errors would be more likely to propagate\n",
    "# as we have to round each time when calculating N\n",
    "# We should also get in the habit of using linspace, as it ensures N points every time.\n",
    "def make_signal(noise_scales, linear_drift, N, meas_rate, seed=None):\n",
    "    # Generate initial linear drift signal\n",
    "    time_steps = np.linspace(0, (N-1)/meas_rate, N) # generate the time steps\n",
    "    signal = linear_drift * time_steps\n",
    "    \n",
    "    white_volatility = noise_scales[0]\n",
    "    brown_volatility = noise_scales[1]\n",
    "    pink_volatility = noise_scales[2]\n",
    "    \n",
    "    # Generate noises\n",
    "    white_noise = generate_white_noise(N, meas_rate, seed)\n",
    "    brown_noise = generate_brown_noise(N, meas_rate, seed)\n",
    "    pink_noise = generate_pink_noise(N, meas_rate, seed)\n",
    "    \n",
    "    #Scale noises according to volatility, and add\n",
    "    signal += white_volatility * white_noise # Add the white noise\n",
    "    signal += brown_volatility * brown_noise # Add the brown noise\n",
    "    signal += pink_volatility * pink_noise # Add the pink noise\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af639218-b0a6-4e06-93c4-805afd93fe92",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Analyze via manual adev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509b1dd8-2fbf-407f-a906-ac301ff6138c",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def analyze_signal(signal, meas_rate, num_taus):\n",
    "    # Plot Signal\n",
    "    N = signal.size\n",
    "    times = np.linspace(0, (N-1)/meas_rate, N)\n",
    "    plt.figure(figsize=(12,3))\n",
    "    plt.plot(times, signal, color='red', alpha=0.5, linewidth=0.5)\n",
    "    plt.xlim(0,(N-1)/meas_rate)\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.title(\"Signal over time\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot PSD\n",
    "    plt.figure(figsize=(12,3))\n",
    "    plt.psd(signal, NFFT=1024, Fs=meas_rate)\n",
    "    plt.title('Power Spectral Density (PSD) of Signal')\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.ylabel('Power')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Perform Allan Dev\n",
    "    #num_taus = 10\n",
    "    base = 10\n",
    "    power = int(np.log(N/2)/np.log(base))\n",
    "    pnts = np.logspace(0, power, num=num_taus, base=base, dtype=int) # exact integer number of points\n",
    "    taus = np.unique(pnts/meas_rate)\n",
    "    avs, al_var, taus = manual_adev(signal, meas_rate, taus)\n",
    "    #print(avs.shape)\n",
    "    plot_adev(avs, al_var, taus)\n",
    "    return taus, al_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af75508-e3b4-4e37-88e3-e78a9fb7317c",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def analyze_measurement(df, column, num_taus):\n",
    "    N = df.shape[0]\n",
    "    T = df['TimeElapsed'][N-1]\n",
    "    meas_rate = (N-1)/T\n",
    "\n",
    "    taus, al_var = analyze_signal(df[column].values, meas_rate, num_taus)\n",
    "    return taus, al_var, meas_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85b83daf-d1fc-4120-b3a6-27e23e34a138",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyze_measurement' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_32372\\3533054745.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtaus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mal_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeas_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyze_measurement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_LS1_1_1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Azimuth'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'analyze_measurement' is not defined"
     ]
    }
   ],
   "source": [
    "taus, al_var, meas_rate = analyze_measurement(df_LS1_1_1024, 'Azimuth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb26f87d-e9d1-4113-a011-3b5329dd74b0",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Parameters for brownian motion\n",
    "gen_meas_rate = 100 # Rate of measurements in Hz\n",
    "T_do_not_use = 100 # Total length of signal in s (here for convinience, but do not use after finding N)\n",
    "gen_N = 1 + int(np.ceil(T_do_not_use*gen_meas_rate)) # Number of measurements (+1 bc t.e. a measurement at 0, too)\n",
    "linear_drift = 1 # Rate of linear drift of signal\n",
    "noise_scales = [8, 2, 0] # How much [white, brown, pink] noise\n",
    "\n",
    "# Make signal\n",
    "gen_signal = make_signal(noise_scales, linear_drift, gen_N, gen_meas_rate, seed=14)\n",
    "\n",
    "gen_taus, gen_al_var = analyze_signal(gen_signal, gen_meas_rate, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81cf981-eb58-4d7d-b213-c7c27bf2de06",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Analyze via packaged adev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb76f408-55c9-4ec7-a81a-afbc48ddf255",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO: compare values between packaged and manual adev\n",
    "(gen_taus2, gen_ad, gen_ade, gen_ns) = allantools.adev(gen_signal, rate = gen_meas_rate, taus=gen_taus, data_type=\"freq\")\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.plot(gen_taus2, gen_ad, marker='o')\n",
    "plt.xlabel(\"Averaging Time\")\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Variance vs averaging time\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6f8f4-97ca-4c36-a01b-aa86af615dcd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# about to compare variances obtained from each method\n",
    "gen_al_var.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f2f4a-39ab-414a-b4fb-b64bd5bd5eb6",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Application to Measured Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b9ede6-f842-4cdc-9b27-54497078aed3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Manual adev analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea65ab4-bfff-4fc3-861d-5f5048cac41f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_pax_params(df_steady_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bdd156-67b9-479d-be32-2dc7ac4f03ed",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "taus, al_var, meas_rate = analyze_measurement(df_steady_long, 'Azimuth', 50)\n",
    "# TODO: plot power on log plot in psd and units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f69d06-d9e4-42cb-aaa8-4dfe8187a253",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "taus, al_var, meas_rate = analyze_measurement(df_steady_long_3, 'Azimuth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe38a2e-d724-4fdd-bc0c-64deaffe9391",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "taus, al_var, meas_rate = analyze_measurement(df_steady_long_4, 'Azimuth', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3702b44e-34b3-4dc2-8bdd-0aaf058386c7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_pax_params(df_plate_2_half_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce6667-1520-403c-b648-34c58f323de3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "taus, al_var, meas_rate = analyze_measurement(df_plate_2_half_1, 'Azimuth', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093146d9-27d1-40ca-a519-1e7b7dbb11f1",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Noise Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ef28c-e44a-4d04-aa83-eae12126c5cd",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N = 100000\n",
    "rate = 100\n",
    "T = N/rate\n",
    "noise_std = 0.5  # Standard deviation of the noise\n",
    "\n",
    "# Generate time axis\n",
    "t = np.arange(0, T, 1/rate)\n",
    "\n",
    "# Generate random pink noise\n",
    "white_noise = np.random.normal(loc=0.0, scale=noise_std, size=N)*np.sqrt(1/N)\n",
    "brown_noise = np.cumsum(white_noise)\n",
    "pink_noise = brown_noise - np.linspace(0, brown_noise[-1], num=N)\n",
    "\n",
    "# Output the time-varying pink noise signal\n",
    "#plt.plot(pink_noise)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 9))\n",
    "\n",
    "# Plot PSD of white noise\n",
    "axs[0].psd(white_noise, NFFT=1024, Fs=100)\n",
    "axs[0].set_title('Power Spectral Density (PSD) of White Noise')\n",
    "axs[0].set_xlabel('Frequency')\n",
    "axs[0].set_ylabel('Power')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot PSD of brown noise\n",
    "axs[1].psd(brown_noise, NFFT=1024, Fs=100)\n",
    "axs[1].set_title('Power Spectral Density (PSD) of Brown Noise')\n",
    "axs[1].set_xlabel('Frequency')\n",
    "axs[1].set_ylabel('Power')\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot PSD of pink noise\n",
    "axs[2].psd(pink_noise, NFFT=1024, Fs=100)\n",
    "axs[2].set_title('Power Spectral Density (PSD) of Pink Noise')\n",
    "axs[2].set_xlabel('Frequency')\n",
    "axs[2].set_ylabel('Power')\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot Added PSDs\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.psd(white_noise+brown_noise, NFFT=1024, Fs=meas_rate)\n",
    "plt.title('Power Spectral Density (PSD) of White and Brown Noise')\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Power')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d62dd0-ab62-49a6-bcc8-dc2f6578956b",
   "metadata": {
    "heading_collapsed": true,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Packaged Allan Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39aebce-1d6f-4339-9458-3253e2ffe180",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_allan(df):\n",
    "    meas_rate = df['TimeElapsed'][df.shape[0]-1] #Total seconds elapsed\n",
    "    meas_rate /= df.shape[0] #divided by total measurements (now is period)\n",
    "    meas_rate **= -1 #get in Hz\n",
    "    aDevStokes = [allantools.oadev(df.values[:,i], rate = meas_rate, taus='all', data_type=\"freq\")\n",
    "               for i in range(5,8)]\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    labels = ['S1', 'S2', 'S3']\n",
    "    for i in range(3):\n",
    "        plt.errorbar(aDevStokes[i][0], aDevStokes[i][1], yerr = aDevStokes[i][2], label = labels[i])\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel('Tau [s]')\n",
    "    plt.ylabel('Deviation [degrees]')\n",
    "    plt.title('Allan Deviation of Stokes Parameters')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b35954-f3c8-466b-ba41-e4ca489dffe4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plotallan(plt, y, rate, taus, style):\n",
    "    (t2, ad, ade, adn) = allantools.oadev(y, rate=rate, data_type=\"freq\", taus=taus)\n",
    "    plt.loglog(t2, ad, style)\n",
    "\n",
    "\n",
    "def plotallan_phase(plt, y, rate, taus, style):\n",
    "    (t2, ad, ade, adn) = allantools.oadev(y, rate=rate, taus=taus)\n",
    "    plt.loglog(t2, ad, style)\n",
    "\n",
    "\n",
    "def plotline(plt, alpha, taus, style):\n",
    "    \"\"\" plot a line with the slope alpha \"\"\"\n",
    "    y = [pow(tt, alpha) for tt in taus]\n",
    "    plt.loglog(taus, y, style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8ff84c-ba55-40df-ae34-960c5ad7b905",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from allantools import noise\n",
    "\n",
    "t = np.logspace(0, 3, 50)  # tau values from 1 to 1000\n",
    "plt.subplot(111, xscale=\"log\", yscale=\"log\")\n",
    "N = 10000\n",
    "\n",
    "# # pink frequency noise => constant ADEV\n",
    "# freq_pink = allantools.noise.pink(N)\n",
    "# phase_p = np.cumsum(allantools.noise.pink(N))  # integrate to get phase, color??\n",
    "# (t2, ad, ade, adn) = allantools.oadev(phase_p, rate=1, taus=t)\n",
    "# plt.loglog(t2, ad, 'co')\n",
    "# (t2, ad, ade, adn) = allantools.oadev(freq_pink, rate=1, data_type=\"freq\", taus=t)\n",
    "# plt.loglog(t2, ad, 'c.')\n",
    "# y = [pow(tt, 0) for tt in t]\n",
    "# plt.loglog(t, y, 'c')\n",
    "\n",
    "# pink frequency noise => constant ADEV\n",
    "freq_pink = noise.pink(N)\n",
    "phase_p = np.cumsum(noise.pink(N))  # integrate to get phase, color??\n",
    "plotallan_phase(plt, phase_p, 1, t, 'co')\n",
    "plotallan(plt, freq_pink, 1, t, 'c.')\n",
    "plotline(plt, 0, t, 'c')\n",
    "\n",
    "# white phase noise => 1/tau ADEV\n",
    "phase_white = noise.white(N)\n",
    "plotallan_phase(plt, phase_white, 1, t, 'ro')\n",
    "freq_w = noise.violet(N)  # diff to get frequency, \"Violet noise\"\n",
    "plotallan(plt, freq_w, 1, t, 'r.')\n",
    "plotline(plt, -1, t, 'r')\n",
    "\n",
    "# white frequency modulation => 1/sqrt(tau) ADEV\n",
    "freq_white = noise.white(N)\n",
    "phase_rw = noise.brown(N)  # integrate to get Brownian, or random walk phase\n",
    "plotallan(plt, freq_white, 1, t, 'b.')\n",
    "plotallan_phase(plt, phase_rw, 1, t, 'bo')\n",
    "plotline(plt, -0.5, t, 'b')\n",
    "\n",
    "\n",
    "# Brownian a.k.a random walk  frequency => sqrt(tau) ADEV\n",
    "freq_rw = noise.brown(N)\n",
    "phase_rw_rw = np.cumsum(noise.brown(N))  # integrate to get  phase\n",
    "plotallan(plt, freq_rw, 1, t, 'm.')\n",
    "plotallan_phase(plt, phase_rw_rw, 1, t, 'mo')\n",
    "plotline(plt, +0.5, t, 'm')\n",
    "\n",
    "plt.xlabel('Tau')\n",
    "plt.ylabel('Overlapping Allan deviation')\n",
    "print(\"Done.\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
